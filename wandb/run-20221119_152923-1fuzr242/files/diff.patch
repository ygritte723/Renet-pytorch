diff --git a/common/utils.py b/common/utils.py
index 0ba9ac5..6105e04 100644
--- a/common/utils.py
+++ b/common/utils.py
@@ -25,7 +25,9 @@ def setup_run(arg_mode='train'):
                    name=args.extra_dir)
 
     if args.dataset == 'miniimagenet':
-        args.num_class = 64
+        args.num_class = 16
+    elif args.dataset == 'miniimagenets':
+        args.num_class = 12
     elif args.dataset == 'cub':
         args.num_class = 100
     elif args.dataset == 'fc100':
@@ -38,6 +40,8 @@ def setup_run(arg_mode='train'):
         args.num_class = 130
     elif args.dataset == 'dogs':
         args.num_class = 70
+    elif args.dataset == 'isic':
+        args.num_class = 4
 
     return args
 
@@ -133,8 +137,8 @@ def parse_args(arg_mode):
 
     ''' about dataset '''
     parser.add_argument('-dataset', type=str, default='miniimagenet',
-                        choices=['miniimagenet', 'cub', 'tieredimagenet', 'cifar_fs'])
-    parser.add_argument('-data_dir', type=str, default='datasets', help='dir of datasets')
+                        choices=['miniimagenet', 'miniimagenets', 'cub', 'tieredimagenet', 'cifar_fs', 'isic'])
+    parser.add_argument('-data_dir', default='/root/autodl-tmp', help='dir of datasets')
 
     ''' about training specs '''
     parser.add_argument('-batch', type=int, default=128, help='auxiliary batch size')
@@ -150,7 +154,7 @@ def parse_args(arg_mode):
 
     ''' about few-shot episodes '''
     parser.add_argument('-way', type=int, default=5, metavar='N', help='number of few-shot classes')
-    parser.add_argument('-shot', type=int, default=1, metavar='K', help='number of shots')
+    parser.add_argument('-shot', type=int, default=5, metavar='K', help='number of shots')
     parser.add_argument('-query', type=int, default=15, help='number of query image per class')
     parser.add_argument('-val_episode', type=int, default=200, help='number of validation episode')
     parser.add_argument('-test_episode', type=int, default=2000, help='number of testing episodes after training')
diff --git a/models/cca.py b/models/cca.py
index 1b35a61..36363d7 100644
--- a/models/cca.py
+++ b/models/cca.py
@@ -11,6 +11,7 @@ class CCA(torch.nn.Module):
         nn_modules = list()
 
         for i in range(num_layers):
+            # 1->16->1
             ch_in = 1 if i == 0 else planes[i - 1]
             ch_out = planes[i]
             k_size = kernel_sizes[i]
diff --git a/models/dataloader/data_utils.py b/models/dataloader/data_utils.py
index a29239e..15a2639 100644
--- a/models/dataloader/data_utils.py
+++ b/models/dataloader/data_utils.py
@@ -6,12 +6,16 @@ def dataset_builder(args):
 
     if args.dataset == 'miniimagenet':
         from models.dataloader.mini_imagenet import MiniImageNet as Dataset
+    elif args.dataset == 'miniimagenets':
+        from models.dataloader.mini_imagenet_s import MiniImageNetS as Dataset
     elif args.dataset == 'cub':
         from models.dataloader.cub import CUB as Dataset
     elif args.dataset == 'tieredimagenet':
         from models.dataloader.tiered_imagenet import tieredImageNet as Dataset
     elif args.dataset == 'cifar_fs':
         from models.dataloader.cifar_fs import DatasetLoader as Dataset
+    elif args.dataset == 'isic':
+        from models.dataloader.isic import ISIC as Dataset
     else:
         raise ValueError('Unkown Dataset')
     return Dataset
diff --git a/models/dataloader/mini_imagenet.py b/models/dataloader/mini_imagenet.py
index 8ab819d..a49ac93 100644
--- a/models/dataloader/mini_imagenet.py
+++ b/models/dataloader/mini_imagenet.py
@@ -9,8 +9,8 @@ import numpy as np
 class MiniImageNet(Dataset):
 
     def __init__(self, setname, args, return_path=False):
-        IMAGE_PATH = os.path.join(args.data_dir, 'miniimagenet/images')
-        SPLIT_PATH = os.path.join(args.data_dir, 'miniimagenet/split')
+        IMAGE_PATH = os.path.join(args.data_dir, 'mini_imagenet/processed_images')
+        SPLIT_PATH = os.path.join(args.data_dir, 'mi_split_16')
 
         csv_path = osp.join(SPLIT_PATH, setname + '.csv')
         lines = [x.strip() for x in open(csv_path, 'r').readlines()][1:]
@@ -23,6 +23,7 @@ class MiniImageNet(Dataset):
         self.args = args
 
         for l in lines:
+            #print(l)
             name, wnid = l.split(',')
             path = osp.join(IMAGE_PATH, name)
             if wnid not in self.wnids:
diff --git a/models/dataloader/samplers.py b/models/dataloader/samplers.py
index d7e0304..bffa4d0 100644
--- a/models/dataloader/samplers.py
+++ b/models/dataloader/samplers.py
@@ -5,16 +5,20 @@ import numpy as np
 class CategoriesSampler():
 
     def __init__(self, label, n_batch, n_cls, n_per):
+        # print(label, n_batch, n_cls, n_per)
         self.n_batch = n_batch  # the number of iterations in the dataloader
-        self.n_cls = n_cls
-        self.n_per = n_per
+        self.n_cls = n_cls #2
+        self.n_per = n_per #20
 
         label = np.array(label)  # all data label
+        #print(label)
         self.m_ind = []  # the data index of each class
         for i in range(max(label) + 1):
             ind = np.argwhere(label == i).reshape(-1)  # all data index of this class
             ind = torch.from_numpy(ind)
+            #print(ind)
             self.m_ind.append(ind)
+        # print(self.m_ind)
 
     def __len__(self):
         return self.n_batch
@@ -22,11 +26,15 @@ class CategoriesSampler():
     def __iter__(self):
         for i_batch in range(self.n_batch):
             batch = []
+            # print(len(self.m_ind))
             classes = torch.randperm(len(self.m_ind))[:self.n_cls]  # random sample num_class indices, e.g. 5
+            # print(classes)
             for c in classes:
                 l = self.m_ind[c]  # all data indices of this class
+            
                 pos = torch.randperm(len(l))[:self.n_per]  # sample n_per data index of this class
                 batch.append(l[pos])
+                # print(len(l[pos]))
             batch = torch.stack(batch).t().reshape(-1)
             # .t() transpose,
             # due to it, the label is in the sequence of abcdabcdabcd form after reshape,
diff --git a/models/renet.py b/models/renet.py
index a2eeb34..1984faa 100644
--- a/models/renet.py
+++ b/models/renet.py
@@ -24,6 +24,7 @@ class RENet(nn.Module):
 
         self.scr_module = self._make_scr_layer(planes=[640, 64, 64, 64, 640])
         self.cca_module = CCA(kernel_sizes=[3, 3], planes=[16, 1])
+        # self.cca_module = CCA(kernel_sizes=[3, 3], planes=[1, 1])
         self.cca_1x1 = nn.Sequential(
             nn.Conv2d(self.encoder_dim, 64, kernel_size=1, bias=False),
             nn.BatchNorm2d(64),
@@ -70,6 +71,7 @@ class RENet(nn.Module):
         return self.fc(x)
 
     def cca(self, spt, qry):
+        # only in dimension 0 input of size 1 removed
         spt = spt.squeeze(0)
 
         # shifting channel activations by the channel mean
@@ -81,6 +83,7 @@ class RENet(nn.Module):
         num_qry, way, H_s, W_s, H_q, W_q = corr4d.size()
 
         # corr4d refinement
+        # convolutional matching C -> h(C)
         corr4d = self.cca_module(corr4d.view(-1, 1, H_s, W_s, H_q, W_q))
         corr4d_s = corr4d.view(num_qry, way, H_s * W_s, H_q, W_q)
         corr4d_q = corr4d.view(num_qry, way, H_s, W_s, H_q * W_q)
@@ -88,7 +91,9 @@ class RENet(nn.Module):
         # normalizing the entities for each side to be zero-mean and unit-variance to stabilize training
         corr4d_s = self.gaussian_normalize(corr4d_s, dim=2)
         corr4d_q = self.gaussian_normalize(corr4d_q, dim=4)
-
+        
+        # C' -> A
+        
         # applying softmax for each side
         corr4d_s = F.softmax(corr4d_s / self.args.temperature_attn, dim=2)
         corr4d_s = corr4d_s.view(num_qry, way, H_s, W_s, H_q, W_q)
@@ -100,6 +105,7 @@ class RENet(nn.Module):
         attn_q = corr4d_q.sum(dim=[2, 3])
 
         # applying attention
+        # attention computation A * F -> s,q
         spt_attended = attn_s.unsqueeze(2) * spt.unsqueeze(0)
         qry_attended = attn_q.unsqueeze(2) * qry.unsqueeze(1)
 
@@ -114,11 +120,13 @@ class RENet(nn.Module):
         # In the implementation, the order is reversed, however, those two ways become eventually the same anyway :)
         spt_attended_pooled = spt_attended.mean(dim=[-1, -2])
         qry_attended_pooled = qry_attended.mean(dim=[-1, -2])
+        # z for Loss_anchor
         qry_pooled = qry.mean(dim=[-1, -2])
 
         similarity_matrix = F.cosine_similarity(spt_attended_pooled, qry_attended_pooled, dim=-1)
 
         if self.training:
+            # Loss_metric & loss_anchor
             return similarity_matrix / self.args.temperature, self.fc(qry_pooled)
         else:
             return similarity_matrix / self.args.temperature
@@ -141,6 +149,7 @@ class RENet(nn.Module):
         num_qry = qry.shape[0]
 
         # reduce channel size via 1x1 conv
+        # F -> F'
         spt = self.cca_1x1(spt)
         qry = self.cca_1x1(qry)
 
@@ -152,6 +161,7 @@ class RENet(nn.Module):
         # num_qry * C * H_q * W_q --> num_qry * way * H_q * W_q
         spt = spt.unsqueeze(0).repeat(num_qry, 1, 1, 1, 1)
         qry = qry.unsqueeze(1).repeat(1, way, 1, 1, 1)
+        # C(xq, xs) = sim( Fq'(xq), Fs'(xs))
         similarity_map_einsum = torch.einsum('qncij,qnckl->qnijkl', spt, qry)
         return similarity_map_einsum
 
@@ -159,13 +169,16 @@ class RENet(nn.Module):
         return x - x.mean(1).unsqueeze(1)
 
     def encode(self, x, do_gap=True):
+        # ResNet Z_q & Z_s
         x = self.encoder(x)
 
         if self.args.self_method:
             identity = x
+            # Z -> R -> g(R)
             x = self.scr_module(x)
 
             if self.args.self_method == 'scr':
+                # F = g(R) + Z
                 x = x + identity
             x = F.relu(x, inplace=True)
 
diff --git a/models/scr.py b/models/scr.py
index 85eab37..1d4ec10 100644
--- a/models/scr.py
+++ b/models/scr.py
@@ -32,6 +32,7 @@ class SCR(nn.Module):
 
         c = x.shape[1]
         x = x.view(b, c, h * w, u, v)
+        # the convolutional block follows a bottleneck structure
         x = self.conv1(x)  # [80, 64, hw, 5, 5] --> [80, 64, hw, 3, 3]
         x = self.conv2(x)  # [80, 64, hw, 3, 3] --> [80, 64, hw, 1, 1]
 
@@ -50,13 +51,14 @@ class SelfCorrelationComputation(nn.Module):
 
     def forward(self, x):
         b, c, h, w = x.shape
-
+        # Z -> R
         x = self.relu(x)
         x = F.normalize(x, dim=1, p=2)
         identity = x
 
         x = self.unfold(x)  # b, cuv, h, w
-        x = x.view(b, c, self.kernel_size[0], self.kernel_size[1], h, w)
+        x = x.view(b, c, self.kernel_size[0], self.kernel_size[1], h, w)# b, c, u, v, h, w
+        
         x = x * identity.unsqueeze(2).unsqueeze(2)  # b, c, u, v, h, w * b, c, 1, 1, h, w
         x = x.permute(0, 1, 4, 5, 2, 3).contiguous()  # b, c, h, w, u, v
         return x
diff --git a/scripts/test/cifar_fs_5w1s.sh b/scripts/test/cifar_fs_5w1s.sh
deleted file mode 100644
index 8b1546f..0000000
--- a/scripts/test/cifar_fs_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python test.py -dataset cifar_fs -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0
diff --git a/scripts/test/cifar_fs_5w5s.sh b/scripts/test/cifar_fs_5w5s.sh
deleted file mode 100644
index 1b4734c..0000000
--- a/scripts/test/cifar_fs_5w5s.sh
+++ /dev/null
@@ -1,2 +0,0 @@
-python test.py -dataset cifar_fs -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0 -shot 5
-
diff --git a/scripts/test/cub_5w1s.sh b/scripts/test/cub_5w1s.sh
deleted file mode 100644
index e7e10a7..0000000
--- a/scripts/test/cub_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python test.py -dataset cub -gpu 1 -extra_dir renet_iccv21 -temperature_attn 2.0
diff --git a/scripts/test/cub_5w5s.sh b/scripts/test/cub_5w5s.sh
deleted file mode 100644
index 7183df9..0000000
--- a/scripts/test/cub_5w5s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python test.py -dataset cub -gpu 1 -extra_dir renet_iccv21 -temperature_attn 2.0 -shot 5
diff --git a/scripts/test/miniimagenet_5w1s.sh b/scripts/test/miniimagenet_5w1s.sh
index 8741467..dd1fc8a 100644
--- a/scripts/test/miniimagenet_5w1s.sh
+++ b/scripts/test/miniimagenet_5w1s.sh
@@ -1 +1 @@
-python test.py -dataset miniimagenet -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0
+python test.py -dataset miniimagenet -gpu 0 -extra_dir renet_iccv21 -temperature_attn 5.0
diff --git a/scripts/test/miniimagenet_5w5s.sh b/scripts/test/miniimagenet_5w5s.sh
index 7e73918..32fecca 100644
--- a/scripts/test/miniimagenet_5w5s.sh
+++ b/scripts/test/miniimagenet_5w5s.sh
@@ -1 +1 @@
-python test.py -dataset miniimagenet -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0 -shot 5
+python test.py -dataset miniimagenet -gpu 0 -extra_dir renet_iccv21 -temperature_attn 5.0 -shot 5
diff --git a/scripts/test/tieredimagenet_5w1s.sh b/scripts/test/tieredimagenet_5w1s.sh
deleted file mode 100644
index 8550a84..0000000
--- a/scripts/test/tieredimagenet_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python test.py -dataset tieredimagenet -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0
diff --git a/scripts/test/tieredimagenet_5w5s.sh b/scripts/test/tieredimagenet_5w5s.sh
deleted file mode 100644
index c51267e..0000000
--- a/scripts/test/tieredimagenet_5w5s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python test.py -dataset tieredimagenet -gpu 1 -extra_dir renet_iccv21 -temperature_attn 5.0 -shot 5
diff --git a/scripts/train/cifar_fs_5w1s.sh b/scripts/train/cifar_fs_5w1s.sh
deleted file mode 100644
index 6c8ca45..0000000
--- a/scripts/train/cifar_fs_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python train.py -batch 64 -dataset cifar_fs -gpu 1 -extra_dir your_run -temperature_attn 5.0 -lamb 0.5
diff --git a/scripts/train/cifar_fs_5w5s.sh b/scripts/train/cifar_fs_5w5s.sh
deleted file mode 100644
index 87f078c..0000000
--- a/scripts/train/cifar_fs_5w5s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python train.py -batch 64 -dataset cifar_fs -gpu 1 -extra_dir your_run -temperature_attn 5.0 -lamb 0.5 -shot 5 -milestones 40 50 -max_epoch 60
diff --git a/scripts/train/cub_5w1s.sh b/scripts/train/cub_5w1s.sh
deleted file mode 100644
index a2d2989..0000000
--- a/scripts/train/cub_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python train.py -batch 64 -dataset cub -gpu 1 -extra_dir your_run -temperature_attn 2.0 -lamb 1.5
\ No newline at end of file
diff --git a/scripts/train/cub_5w5s.sh b/scripts/train/cub_5w5s.sh
deleted file mode 100644
index 1f73b18..0000000
--- a/scripts/train/cub_5w5s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python train.py -batch 64 -dataset cub -gpu 1 -extra_dir your_run -temperature_attn 2.0 -lamb 1.5 -shot 5 -milestones 40 50 -max_epoch 60
diff --git a/scripts/train/miniimagenet_5w1s.sh b/scripts/train/miniimagenet_5w1s.sh
index e1b8784..06a5486 100644
--- a/scripts/train/miniimagenet_5w1s.sh
+++ b/scripts/train/miniimagenet_5w1s.sh
@@ -1 +1 @@
-python train.py -batch 128 -dataset miniimagenet -gpu 1 -extra_dir your_run -temperature_attn 5.0 -lamb 0.25
+python train.py -batch 128 -dataset miniimagenet -gpu 0 -extra_dir your_run -temperature_attn 5.0 -lamb 0.25
diff --git a/scripts/train/miniimagenet_5w5s.sh b/scripts/train/miniimagenet_5w5s.sh
index 96d7f55..ccfbb72 100644
--- a/scripts/train/miniimagenet_5w5s.sh
+++ b/scripts/train/miniimagenet_5w5s.sh
@@ -1 +1 @@
-python train.py -batch 128 -dataset miniimagenet -gpu 1 -extra_dir your_run -temperature_attn 5.0 -lamb 0.25 -shot 5 -milestones 40 50 -max_epoch 60
+python train.py -batch 128 -dataset miniimagenet -gpu 0 -extra_dir your_run_16 -temperature_attn 5.0 -lamb 0.25 -shot 5 -milestones 40 50 -max_epoch 60
diff --git a/scripts/train/tieredimagenet_5w1s.sh b/scripts/train/tieredimagenet_5w1s.sh
deleted file mode 100644
index 335f2f4..0000000
--- a/scripts/train/tieredimagenet_5w1s.sh
+++ /dev/null
@@ -1 +0,0 @@
-python train.py -batch 256 -dataset tieredimagenet -gpu 1,0 -extra_dir your_run -temperature_attn 5.0 -lamb 0.25 -milestones 60 80 -max_epoch 100
diff --git a/scripts/train/tieredimagenet_5w5s.sh b/scripts/train/tieredimagenet_5w5s.sh
deleted file mode 100644
index 268cdda..0000000
--- a/scripts/train/tieredimagenet_5w5s.sh
+++ /dev/null
@@ -1,2 +0,0 @@
-python train.py -batch 256 -dataset tieredimagenet -gpu 1,0 -extra_dir your_run -temperature_attn 5.0 -lamb 0.25 -shot 5 -milestones 40 50 -max_epoch 60
-
diff --git a/train.py b/train.py
index 901470e..1297382 100644
--- a/train.py
+++ b/train.py
@@ -31,19 +31,22 @@ def train(epoch, model, loader, optimizer, args=None):
     k = args.way * args.shot
     tqdm_gen = tqdm.tqdm(train_loader)
 
+    # Begin at 1
     for i, ((data, train_labels), (data_aux, train_labels_aux)) in enumerate(zip(tqdm_gen, train_loader_aux), 1):
 
         data, train_labels = data.cuda(), train_labels.cuda()
         data_aux, train_labels_aux = data_aux.cuda(), train_labels_aux.cuda()
 
-        # Forward images (3, 84, 84) -> (C, H, W)
+        # Forward images (3, 84, 84) -> (C, H, W) 
         model.module.mode = 'encoder'
         data = model(data)
         data_aux = model(data_aux)  # I prefer to separate feed-forwarding data and data_aux due to BN
 
         # loss for batch
         model.module.mode = 'cca'
+        # k = way*shot
         data_shot, data_query = data[:k], data[k:]
+        # cca: data_shot vs data_query
         logits, absolute_logits = model((data_shot.unsqueeze(0).repeat(args.num_gpu, 1, 1, 1, 1), data_query))
         epi_loss = F.cross_entropy(logits, label)
         absolute_loss = F.cross_entropy(absolute_logits, train_labels[k:])
@@ -54,7 +57,9 @@ def train(epoch, model, loader, optimizer, args=None):
         loss_aux = F.cross_entropy(logits_aux, train_labels_aux)
         loss_aux = loss_aux + absolute_loss
 
+        # lambda
         loss = args.lamb * epi_loss + loss_aux
+        
         acc = compute_accuracy(logits, label)
 
         loss_meter.update(loss.item())
